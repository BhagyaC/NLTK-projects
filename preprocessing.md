# Preprocessing

- corpus creation 
- make the text suitable for prediction
- Understanding the problem is very cruicial for preprocessing
- improper method may cause the loosing lexical data
- tokenisation , normalisation  ,substitution
- tokenisation along with stemming , lemmatization , remove the mispelling and puctuations
- substitution is converting every value to a standard unit
- lower casing of the text is also done
- before any ML algorithm there are many machine learning steps to be done
- for example if we are using the html then first convert it to the text --> lowercase --> case folding --> remove the script --> tokenise --> TF --> extract vocabulary --> remove stop words --> stemming and lemmatization
