Text Analysis

step 1: Tokenization

Tokenization is the first step in text analytics.
The process of breaking down a text paragraph into smaller chunks such as words or sentence is called Tokenization. 
Token is a single entity that is building blocks for sentence or paragraph.


