# Text Analysis

###step 1: Tokenization

Tokenization is the first step in text analytics.
The process of breaking down a text paragraph into smaller chunks such as words or sentence is called Tokenization. 
Token is a single entity that is building blocks for sentence or paragraph.


tokenization take place for both sentence and word

a.Sentence Tokenization

Sentence tokenizer breaks text paragraph into sentences.

b.Word Tokenization

Word tokenizer breaks text paragraph into words.

### step 2:Frequency Distribution

### step 3:Stopwords

Stopwords considered as noise in the text. Text may contain stop words such as is, am, are, this, a, an, the, etc.
In NLTK for removing stopwords, you need to create a list of stopwords and filter out your list of tokens from these words.

### step 4:Lexicon Normalization

It is considered as another type of noise in text
The words are reduces to the root words

a.stemming:
removes the derivational affixes

b.lemmatization
which focuses on ligustically correct leammas
It transforms to the root words by morphological and vocabulary analysis 

### step 5: POS Tagging

Its is part of speech tagging it is to identify gramatical group of given word


